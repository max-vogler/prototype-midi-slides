<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>
      Rapidly Prototyping MIDI Controllers with Web MIDI - Max Vogler
    </title>

    <link rel="stylesheet" href="dist/reset.css" />
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="dist/theme/black.css" id="theme" />
    <link
      rel="stylesheet"
      href="plugin/highlight/monokai-sublime.css"
      id="highlight-theme"
    />
    <link rel="stylesheet" href="dist/custom.css" />
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section data-transition="fade-out">
          <h3>Rapidly Prototyping<br>MIDI Controllers<br>with Web MIDI</h3>
          <img src="images/icons/5835702_music_control_effect_fx_icon.svg" class="icon">
          <p>
            Max Vogler, Web Audio Conference 2021<br>
            <a href="https://github.com/max-vogler/midi">github.com/max-vogler/midi</a>
          </p>
          <aside class="notes" data-markdown>
            Hey Web Audio Conf.

            Welcome to the sneak peek of prototyping MIDI Controllers with web technologies.
            
            My name is Max and in the next couple minutes minutes I'll build a touch-enabled MIDI controller in only
            15 lines of JavaScript.
            
            I'm super excited to speak at Web Audio Conf 2021. 
            
            My full talk will be more in-depth and cover topics like gamepad input, peer-to-peer connection and computer vision.
          </aside>
        </section>
        <section data-transition="fade-in" data-auto-animate>
          <h3><span></span><span data-id="h">MIDI</span></h3>

          <div class="row">
            <img src="images/icons/5835707_controller_launchpad_live_midi_icon.svg" style="width: 15vw;" class="fragment fade-in">
          </div>

          <aside class="notes" data-markdown>
            First, what are MIDI controllers?

            The MIDI standard allows audio devices and software to send messages to each other.

            For example, in the DJing space, hardware DJ controllers with 

            ➡️ buttons,

            ➡️ keys, faders,

            ➡️ jog wheels and rotary knobs are connected to a laptop
          </aside>
        </section>
        <section data-auto-animate>
          <h3><span></span><span data-id="h">MIDI</span></h3>

          <div class="row">
            <img src="images/icons/5835707_controller_launchpad_live_midi_icon.svg" style="width: 15vw;">
            <img src="images/icons/5835708_electric_keyboard_piano_workstation_icon.svg" style="width: 15vw;">
          </div>

          <aside class="notes" data-markdown>
            First, what are MIDI controllers?

            The MIDI standard allows audio devices and software to send messages to each other.

            For example, in the DJing space, hardware DJ controllers with 

            ➡️ buttons,

            ➡️ keys, faders,

            ➡️ jog wheels and rotary knobs are connected to a laptop
          </aside>
        </section>
         <section data-auto-animate>
          <h3><span></span><span data-id="h">MIDI</span></h3>

          <div class="row">
            <img src="images/icons/5835707_controller_launchpad_live_midi_icon.svg" style="width: 15vw;">
            <img src="images/icons/5835708_electric_keyboard_piano_workstation_icon.svg" style="width: 15vw;">
            <img src="images/icons/5835749_control_dj_mixing_sampler_icon.svg" style="width: 15vw;">
          </div>

          <aside class="notes" data-markdown>
            First, what are MIDI controllers?

            The MIDI standard allows audio devices and software to send messages to each other.

            For example, in the DJing space, hardware DJ controllers with 

            ➡️ buttons,

            ➡️ keys, faders,

            ➡️ jog wheels and rotary knobs are connected to a laptop
          </aside>
        </section>
        <section data-auto-animate>
          <h3><span></span><span data-id="h">MIDI</span></h3>

          <img src="images/screenshots/beatportdj.png" data-id="d1">

          <div class="row">
            <img src="images/icons/5835707_controller_launchpad_live_midi_icon.svg" style="width: 15vw;">
            <img src="images/icons/5835708_electric_keyboard_piano_workstation_icon.svg" style="width: 15vw;">
            <img src="images/icons/5835749_control_dj_mixing_sampler_icon.svg" style="width: 15vw;">
          </div>

          <aside class="notes" data-markdown>
            and send messages to a DJ software to control music playback and effects.

            Building hardware controllers or standalone applications can require extensive knowledge and resources.
            
            Prototypes and experiments can also suffer from long iteration times.

            Using the Web MIDI JavaScript API,
          </aside>
        </section>
        <section data-auto-animate>
          <h3><span>Web</span> <span data-id="h">MIDI</span></h3>

          <div class="browser-mockup" style="font-size: 16px;">
            <div class="url">https://dj.beatport.com/</div>
            <img src="images/screenshots/beatportdj.png" data-id="d1">
          </div>

          <div class="row">
            <div class="browser-mockup" style="font-size: 8px; width: 15vw;">
              <div class="url">https://midi.maxvogler.de/</div>
              <img src="images/icons/5835707_controller_launchpad_live_midi_icon.svg">
            </div>

            <div class="browser-mockup" style="font-size: 8px; width: 15vw;">
              <div class="url">https://midi.maxvogler.de/</div>
              <img src="images/icons/5835708_electric_keyboard_piano_workstation_icon.svg">
            </div>
            
            <div class="browser-mockup" style="font-size: 8px; width: 15vw;">
              <div class="url">https://midi.maxvogler.de/</div>
              <img src="images/icons/5835749_control_dj_mixing_sampler_icon.svg">
            </div>
          </div>

          <aside class="notes" data-markdown>
            the browser can now connect to these MIDI devices.

            Programming with Web MIDI requires no compilation and gives you access to the huge amount
            of JavaScript libraries and web technologies.
            
            This makes Web MIDI the perfect platform for prototypes and experiments.

            Alright, let's get started:
          </aside>
        </section>
        <section>
          <h3>Accessing Web MIDI ports</h3>
          <pre><code data-trim class="language-html" data-line-numbers="2|3-5|6-20">
            &lt;!doctype html&gt;&lt;script type="module"&gt;
            const midi = await navigator.requestMIDIAccess();
            const getMIDIOutputs = () => [...midi.outputs.values()];
            await Promise.all(getMIDIOutputs().map(o => o.open()));

            const sendMIDIMessage = (message) =>
              getMIDIOutputs().forEach((output) =>
                output.send(message));
          </code></pre>
          <aside class="notes" data-markdown>
            To gain access to all MIDI devices that are connected to your computer, call requestMIDIAccess.
            
            ➡️ We use the returned MidiAccess instance to iterate over all output ports and open each one of them.

            ➡️ Then, we define a helper function, sendMidiMessage, that broadcasts a given message to all output ports.
          </aside>
        </section>
        <section>
          <h3>Sending MIDI messages</h3>
          <pre><code data-trim class="language-javascript" data-line-numbers="1-3|5-7|9-12">
            // MIDI message format: [command, pitch, velocity]
            const noteOn = (pitch, velocity) => sendMIDIMessage(
              [0x90, pitch, Math.round(velocity * 127)]);

            // In MIDI standard, messages describe notes on a piano:
            noteOn(0, 1)   // Hit lowest C note with full velocity.
            noteOn(1, 0.1) // Hit lowest C# note lightly.

            // DJ software can map the same messages differently:
            noteOn(0, 1)   // Move crossfader to the right.
            noteOn(1, 0.1) // Set effect dry/wet to 10%.
            noteOn(2, 1)   // Press button, spin jog wheel, …
          </code></pre>

          <aside class="notes" data-markdown>
            Now, we define another helper function, noteOn that sends a MIDI noteOn command, identified by hex 90,
            a pitch and velocity.

            ➡️ In the MIDI standard, noteOn messages refer to hitting notes on a piano.
            A pitch of 0 maps to the lowest C note and velocity maps to how hard this key has been hit.

            ➡️ Audio software and other MIDI devices understand the same messages,
            but map them to different things, for example, moving a crossfader or changing effects.
            Pitch and velocity no longer necessarily have a musical meaning. My DJ software treats
            the pitch more as a data channel id and velocity as the data value.
          </aside>
        </section>
        <section>
          <h3>Prototype: 3D Touch Controller</h3>
          <img src="images/flaticon.com/touch.svg" class="icon">
          <aside class="notes" data-markdown>
            Let's use these functions to build our first prototype: 
            
            People access the web with a variety of input devices, including the touchscreen,
            trackpad, mouse, and stylus. Browser vendors put a lot of work to make websites accessible 
            for all these different input modes. This has been abstracted for us into the Web Pointer Events API. 
            
            We'll piggyback on this work and build a widely usable MIDI controller. It will control three
            parameters at once by tracking the user's pointer location and pressure.
          </aside>
        </section>

        <section>
          <pre><code data-trim class="language-javascript" data-line-numbers="1-3,5,11,19-20">
            document.addEventListener("pointermove", (event) => {});

            { // PointerEvent
              button: -1,
              buttons: 1,
              height: 1,
              movementX: -3,
              movementY: 2,
              pointerId: 1,
              pointerType: "mouse",
              pressure: 0.5,
              tangentialPressure: 0,
              tiltX: 0,
              tiltY: 0,
              timeStamp: 28038.30000001192,
              twist: 0,
              type: "pointermove",
              width: 1,
              x: 217.86328125,
              y: 719.2265625,
              // …
          </code></pre>
        </section>

        <section>
          <h3>Translating touch events to MIDI</h3>
          <pre><code data-trim class="language-javascript" data-line-numbers="1-2,7|3|4-5|6">
            document.addEventListener("pointermove",
              ({x, y, pressure, buttons}) => {
                const sendOnOrOff = buttons ? noteOn : noteOff;
                sendOnOrOff(0, x / window.innerWidth);
                sendOnOrOff(1, y / window.innerHeight);
                sendOnOrOff(2, pressure);
              });
          </code></pre>
          <aside class="notes" data-markdown>
            To use this API, we register a pointermove event listener that is called
            whenever the pointer's position changes. This happens when the user moves their finger on
            the trackpad or touchscreen or moves the mouse.
            The pointer's absolute x and y position, normalized touch pressure, and any button presses are passed into our callback.

            ➡️ First, we alias our helper functions. If the screen or mouse button has been pressed, we call noteOn.
            If the user does not press the mouse button or only hovers the trackpad, we call noteOff.

            ➡️ Next, we normalize the x and y position in relation to the window size.
              These two values will be sent as MIDI messages with pitch 0 and 1.

            ➡️ Finally, the touch pressure will be sent as message with pitch 2.

            Ultimately, this code sends three MIDI messages whenever the user moves their finger. Now, let's run this prototype.
          </aside>
        </section>
        <section>
          <div class="browser-mockup" class="r-stretch">
            <div class="url">https://midi.maxvogler.de/touch/</div>
            <iframe data-src="https://midi.maxvogler.de/touch/" allow="midi"></iframe>

            <aside class="notes" data-markdown>
              All these slides have been built with web technologies and run right in the browser.
              On this slide, you see two Web MIDI devices. The browser frame runs the code from the previous slildes.
              I did add some polishing, for example rendering the coordinates. In the bottom of a slide,
              you see a MIDI input that displays message velocity in the three indicators. To connect the two, I 
              configured a MIDI loopback software on my computer, that passes messages from the touch controller to the indicators.

              Moving the pointer horizontally controls the value of the pitch 0, which is displayed in the left indicator. Vertical
              movements are shown in the center. The touch pressure is shown on the right. My mouse reports all clicks as having 50% pressure.

              Controlling three signals with one hand or finger is very powerful. For example, we could map these to a delay effect
              where horizontal movements control the wetness, vertical the rate, and pressure the feedback.
            </aside>
          </div>
          
          <aside class="midi-debug">
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
          </aside>
        </section>
        <section>
          <p>That is how you prototype a<br>3D Touch MIDI controller<br> in 15 lines of code.</p>
          <img src="images/flaticon.com/fireworks.svg" class="icon">

          <aside class="notes" data-markdown>
            And that's how you prototype a MIDI controller in only 15 lines of code. You can find
            the whole code licensed under MIT at the linked GitHub Repo.
          </aside>
        </section>
        
        
        <!--
        <section>
          <h3>See you at Web Audio Conf</h3>
          <img src="images/flaticon.com/gamepad.svg" class="icon fragment fade-up" style="margin: 0 20px;">
          <img src="images/flaticon.com/computer.svg" class="icon fragment fade-up" style="margin: 0 20px;">
          <img src="images/flaticon.com/monitoring.svg" class="icon fragment fade-up" style="margin: 0 20px;">

          <aside class="notes" data-markdown>
            I'm excited to share more in-depth prototypes with you at Web Audio Conf and talk about future possibilities and technical limitations.
            
            My full talk will feature:
            
            ➡️ controlling audio with my XBOX controller, 

            ➡️ connecting remote MIDI devices with a WebRTC peer-to-peer connection, and 

            ➡️ controlling effects through hand gestures in front of the webcam.

            See you at Web Audio Conf.
          </aside>
        </section>
        -->
        
        <section>
          <h3>Prototype: Gamepad Controller</h3>
          <img src="images/flaticon.com/gamepad.svg" class="icon">
        </section>
        <section>
          <pre class="r-stretch"><code data-trim class="langauge-javascript">
          navigator.getGamepads()  # => Gamepad[]

          [{
            axes: [
               0.041061997413635,
              -0.175371944904327,
              -0.701930284500122,
              -0.928191065788269,
            ],
            buttons: [
              {pressed: false, touched: false, value: 0},
              {pressed: true,  touched: true,  value: 1},
              {pressed: true,  touched: true,  value: 0.52156869},
              // …
            ],
            connected: true,
            id: "Xbox One Wired Controller (STANDARD GAMEPAD Vendor: 045e Product: 02ea)",
            index: 0,
            mapping: "standard",
            timestamp: 227490.80000001192,
            vibrationActuator: null,
          }]
          </code></pre>
        </section>
        <section>
          <pre class="r-stretch"><code data-trim class="language-javascript"  data-line-numbers="1-3|5-7|9-13|14-99">           
            window.addEventListener("gamepadconnected", () => {
              requestAnimationFrame(gamePadProcessLoop);
            });

            function gamePadProcessLoop() {
              requestAnimationFrame(gamePadProcessLoop);
              const gamepad = navigator.getGamepads()[0];

              gamepad.buttons.forEach((button, i) => {
                const send = button.value ? noteOn : noteOff;
                send(i, button.value);
              });

              gamepad.axes.forEach((axis, i) => {
                const send = Math.abs(axis) < 0.1 ? noteOn : noteOff;
                send(gamepad.buttons.length + i, axis / 2 + 0.5);
              }); 
            }
          </code></pre>
        </section>

        <section>
          <div class="browser-mockup" class="r-stretch">
            <div class="url">https://midi.maxvogler.de/controller/</div>
            <iframe data-src="https://midi.maxvogler.de/controller/" allow="gamepad; midi"></iframe>
          </div>
          
          <aside class="midi-debug">
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
          </aside>
        </section>

        <section>
          <h3>Prototype: WebRTC P2P Controller</h3>
          <img src="images/flaticon.com/computer.svg" class="icon">
        </section>

        <section>
          <h3>Receive MIDI messages through WebRTC</h3>
          <pre class="r-stretch"><code data-trim class="language-javascript"  data-line-numbers="1-3|5-9|11-99">           
             const peer = new Peer()
              .on("open", onPeerOpen)
              .on("connection", initConnection);

            function onPeerOpen(id) {
              const canvas = document.querySelector("canvas");
              const url = `https://midi.maxvogler.de/touch/#${id}`;
              QRCode.toCanvas(canvas, url);
            }

            function initConnection(connection) {
              connection.on("data", (message) => {
                messages.forEach(msg => sendMIDIMessage(msg));
              });
            }
          </code></pre>
        </section>

        <section>
          <h3>Send MIDI messages through WebRTC</h3>
          <pre class="r-stretch"><code data-trim class="language-javascript"  data-line-numbers="1-6|8-99">           
            let connection;

            const peer = new Peer().on("open", () => {
              const receiverId = window.location.hash.substr(1);
              connection = peer.connect(receiverId);
            });

            document.addEventListener("pointermove",
              ({pressure}) => {
                connection.send([
                  …
                  [0x90, 0, pressure],
                ]);
              });
          </code></pre>
        </section>

        <section>
          <div class="browser-mockup" class="r-stretch">
            <div class="url">https://midi.maxvogler.de/gateway/</div>
            <iframe data-src="https://midi.maxvogler.de/gateway/" allow="gamepad; midi"></iframe>
          </div>
          
          <aside class="midi-debug">
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
          </aside>
        </section>

        <section>
          <h3>Prototype: TFJS Handpose Controller</h3>
          <img src="images/flaticon.com/monitoring.svg" class="icon">
        </section>

        <section>
          <pre class="r-stretch"><code data-trim class="language-javascript">
            await model.estimateHands(video)  // => Prediction[]

            [{
              "handInViewConfidence": 0.9999556541442871,
              "boundingBox": {
                  "topLeft":     [ 28.1298146,  19.8936638],
                  "bottomRight": [247.2517192, 239.0155685],
              },
              "annotations": {
                  "thumb": [ … ],
                  "indexFinger":  [
                    [151.02550626, 206.21306088, 13.06605720],
                    [174.06625332, 193.85526167, 22.90657806],
                    [188.86545223, 185.76264153, 30.54719924],
                    [196.11875342, 180.25369840, 39.67101287],
                  ],
                  "middleFinger": [ … ],
                  "ringFinger":   [ … ],
                  "pinky":        [ … ],
                  "palmBase": [
                    [115.1016626, 209.1353088, 0.0000614],
                  ]
              }}]
          </code></pre>
        </section>
        <section>
          <pre class="r-stretch"><code data-trim class="language-javascript" data-line-numbers="1-4|6-7|9-10|12-14|15-17|19-20">
            const video = document.querySelector("video");
            video.srcObject = await navigator.mediaDevices.getUserMedia(
              {audio: false, video: {facingMode: "user"}});
            video.play();

            const model = await handpose.load(); 
            processVideoLoop();

            async function processVideoLoop() {
              const predictions = await model.estimateHands(video);

              if (predictions.length > 0) {
                noteOn(0, calculateHandOpenness(
                    predictions[0].annotations));
              } else {
                noteOff(0, 0);
              }

              requestAnimationFrame(processVideoLoop);
            }
          </code></pre>
        </section>

        <section>
          <pre class="r-stretch"><code data-trim class="language-javascript" data-line-numbers="1-2|3-5|6-7|9-14|16-99">
            function calculateHandOpenness(handPoints) {
              const { palmBase, thumb, ...fingers } = handPoints;
              const openness = Object.values(fingers).map((points) =>
                calculateFingerOpenness(palmBase[0], points)
              );
              return Math.min(1, Math.max(0, median(openness)));
            }

            function calculateFingerOpenness(palm, fingerPoints) {
              const distToBase = distance(palm, fingerPoints[0]);
              const distToTip = distance(palm, fingerPoints[4]);
              return 0.3 + 0.8 * 
                ((distToTip - distToBase) / distToBase);
            }

            function distance([ax, ay], [bx, by]) {
              return Math.sqrt((bx - ax) ** 2 + (by - ay) ** 2);
            }
          </code></pre>
        </section>

        <section>
          <div class="browser-mockup" class="r-stretch">
            <div class="url">https://midi.maxvogler.de/handpose/</div>
            <iframe data-src="https://midi.maxvogler.de/handpose/" allow="camera; midi"></iframe>
          </div>
          
          <aside class="midi-debug">
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
            <div class="gauge-container">
              <div class="gauge-a"></div>
              <div class="gauge-b"></div>
              <div class="gauge-c"></div>
            </div>
          </aside>
        </section>

        <section>
          <h3>tl;dr:</h3>

          <ol>
            <li>Web platform provides access to input devices, sensor data, data streams.</li>
            <li>Web MIDI trivially integrates with audio applications.</li>
            <li>Combine both to prototype new MIDI controllers in minutes.</li>
            <li>Have fun, but watch out for stability and latency.</li>
          </ol>
        </section>

        <section>
          <h3>Future</h3>

          <ul>
            <li>Generate MIDI inputs with AI
              <ul><li><a href="https://magenta.tensorflow.org/studio">Magenta Generate</a></li></ul></li>
            <li>Integrate with HID devices
              <ul><li>dance pads, workout machines</li></ul></li>
            <li>Interact with livestream viewers
              <ul><li>Twitch messages</li></ul></li>
            <li>Interact with in-person viewers
              <ul><li>handpose detection, link phones</li></ul></li>
            <li>Connect remote artists to play together</li>
            <li>Interact with live data streams</li>
          </ul>
        </section>

        <section>
          <h3>Credits</h3>
          
          <ul>
            <li>
              Prototypes (MIT): 
              <a href="https://github.com/max-vogler/midi">github.com/max-vogler/midi</a>
            </li>
            <li>
              <a href="https://github.com/soldair/node-qrcode">QRCode</a>,
              <a href="https://github.com/peers/peerjs">PeerJS</a>,
              <a href="https://github.com/peers/peerjs">reveal.js</a> (MIT)
            </li>
            <li>
              <a href="https://github.com/tensorflow/tfjs">tfjs</a>, 
              <a href="https://www.npmjs.com/package/@tensorflow-models/handpose">handpose model</a>
              (Apache-2.0)
            </li>
            <li>Gamepad viz from <a href="https://gamepadviewer.com/">gamepadviewer.com</a>
            <li><a href="https://www.flaticon.com/authors/flat-icons" title="Flat Icons">Flat Icons</a> from <a href="https://www.flaticon.com/" title="Flaticon">www.flaticon.com</a></li>
          </ul>
        </section>
        
        <section>
          <div class="browser-mockup" class="r-stretch">
            <div class="url">https://midi.maxvogler.de/latency/</div>
            <iframe data-src="https://midi.maxvogler.de/latency/" allow="midi"></iframe>
          </div>
        </section>
      </div>
    </div>

    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script type="module">
      import {Reveal, initialize} from "/dist/reveal.esm.js";

      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes],
      });

      initialize(Reveal);
    </script>
  </body>
</html>
